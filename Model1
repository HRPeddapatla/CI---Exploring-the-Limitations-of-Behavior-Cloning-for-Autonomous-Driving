import torch
import torch.nn as nn
import torchvision
import glob
import json
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

!unzip /content/drive/MyDrive/HuskyTrainingData.zip -d HuskyTrainingData

# define a helper function to help read in measurement files
def read_json_file(file):
    with open(file, "r") as r:
        response = r.read()
        response = response.replace('\n', '')
        response = response.replace('}{', '},{')
        response = "[" + response + "]"
        return json.loads(response)

# define a function to create a dataframe with current data
def init_df():
  image_files = glob.glob("/content/HuskyTrainingData/2023-02-08-14-51-49/front_images/*.jpg")
  measurement_files = glob.glob("/content/HuskyTrainingData/2023-02-08-14-51-49/measurements/*.txt")

  image_files.sort()
  measurement_files.sort()

  linear_array = []
  angular_array = []

  for file in measurement_files:
    measure_data = read_json_file(file)
    # take the last measurements in file
    linear_array.append(measure_data[-1]["linear"]["x"])
    angular_array.append(measure_data[-1]["angular"]["z"])
    # store all data in dict
  data_dict = {"image": image_files, "linear": linear_array, "angular": angular_array}
  # convert dict to dataframe
  df = pd.DataFrame(data_dict)

  return df

df = init_df()

df


class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)
        self.conv2 = nn.Conv2d(64, 16, kernel_size=3, stride=3)
        self.bn2 = nn.BatchNorm2d(16)
        self.conv3 = nn.Conv2d(16, 8, kernel_size=2, stride=2)
        self.conv4 = nn.Conv2d(8, 4, kernel_size=3, stride=3)
        self.conv5 = nn.Conv2d(4, 2, kernel_size=1, stride=2)
        self.fc = nn.Linear(2, 2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = x.squeeze()
        return x


def train(model, train_loader, criterion, optimizer, num_epochs):
    loss_values = []
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(train_loader, 0):
            # Get inputs and labels from data loader
            inputs, labels = data

            # Reshape the target tensor to have a spatial dimension
            labels = labels.view(-1)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass, backward pass, and optimize
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # Print statistics
            running_loss += loss.item()
            if i % 10 == 9:
                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))
                loss_values.append(running_loss / 10)
                running_loss = 0.0
    print('Finished Training')
    return loss_values


# Deep Learning data loading and preprocessing
train_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((224, 224)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
train_data = torchvision.datasets.ImageFolder(root='/content/HuskyTrainingData', transform=train_transform)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)

# Deep Learning loss function and optimizer
model = Network()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Model Training
num_epochs = 10
loss_values = train(model, train_loader, criterion, optimizer, num_epochs)

# plot the loss values
plt.plot(loss_values)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.show()
